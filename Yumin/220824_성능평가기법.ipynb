{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (참조) 성능평가지표(Evaluation Metric)\n",
    "\n",
    "> Date: 2022.08.24\n",
    "\n",
    "> Reference:     https://sumniya.tistory.com/26    https://mizykk.tistory.com/102\n",
    "\n",
    "---\n",
    "\n",
    "### 회귀분석\n",
    "- MAE \n",
    "- MSE\n",
    "- RMSE\n",
    "- MSLE\n",
    "- MAPE\n",
    "\n",
    "\n",
    "### 분류분석\n",
    "- Accuracy(정확도)\n",
    "- Confusion Matrix (혼동행렬)\n",
    "- Precision(정밀도) & Recall(재현율)\n",
    "- F1 Score\n",
    "- ROC Curve & AUC Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "### 1. 분류분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99DC064C5BE056CE10\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "(Accuracy) = {TP+TN} / {TP+FN+FP+TN}\n",
    "$$\n",
    "\n",
    "- 가장 직관적으로 모델의 성능을 나타낼 수 있는 평가지표\n",
    "\n",
    "- But domain의 편중 고려 필요 (데이터 구성에 따라 모델의 성능 왜곡 가능성 존재)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- True Positive (TP) : 실제 True인 정답을 True라고 예측 (정답)\n",
    "- False Positive (FP) : 실제 False인 정답을 True라고 예측 (오답)\n",
    "- False Negative (FN) : 실제 True인 정답을 False라고 예측 (오답)\n",
    "- True Negative (TN) : 실제 False인 정답을 False라고 예측 (정답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 사이킷런 API 호출\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 정밀도와 재현율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정밀도\n",
    "\n",
    "모델이 True라고 분류한 것들 중에서 실제 True인 것들의 비율\n",
    "\n",
    "$$\n",
    "(Precision) = TP~/~TP + FP\n",
    "$$\n",
    "\n",
    "> 날씨 예측 모델이 맑다 로 예측했는데, 실제로 날씨가 맑았는지를 살펴보는 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 정밀도\n",
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재현율\n",
    "\n",
    "실제 True인 것들 중에서 모델이 True라고 예측한 것의 비율\n",
    "\n",
    "$$\n",
    "(Recall) = TP~/~TP + FN\n",
    "$$\n",
    "\n",
    "> 실제 날씨가 맑은 날들중, 모델이 날씨가 맑다고 맞춘 비율을 살펴보는 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 재현율\n",
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) F1 스코어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision(정밀도) 와 Recall(재현율) 의 조화평균\n",
    "\n",
    "$$\n",
    "(F1~Score) = 2~*~(Precision~*~Recall)~/~(Precision+Recall)\n",
    "$$\n",
    "\n",
    "> 데이터 label이 불균형 구조일 때 모델의 성능을 정확하게 평가할 수 있음\n",
    "\n",
    "> 단순 산술 평균으로 사용하지 않는 이유 : 산술평균을 이용하는 것보다 큰 비중이 끼치는 영향이 줄어들게 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) ROC 곡선과 AUC 스코어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC 곡선 \n",
    "\n",
    "FPR의 변화에 따른 TPR의 변화를 나타내는 곡선\n",
    "\n",
    "AUC Score\n",
    "\n",
    "ROC curve 아래의 면적을 분류 성능지표로 활용한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROC 곡선\n",
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import roc_curve\n",
    "# FPR, TPR, 임곗값 할당하기\n",
    "fpr, tpr, thres = roc_curve(y_test, y_pred, pos_label = 1)\n",
    "# ROC 곡선 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUC 스코어\n",
    "# 사이킷런 API\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# FPR, TPR, 임곗값 할당하기\n",
    "fpr, tpr, thres = roc_curve(y_test, y_pred, pos_label = 1)\n",
    "# AUC 값\n",
    "auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 회귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) MAE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbGEngr%2FbtqPWZxFSQR%2FkMkdAx0exHjw2HA8Eezbkk%2Fimg.jpg\">\n",
    "\n",
    "- 실제 값과 예측 값의 차이(Error)를 절대값으로 변환해 평균화\n",
    "\n",
    "- 에러에 절대값을 취하므로 에러의 크기가 그대로 반영됨. 따라서 예측 결과물의 에러가 10이 나온 것이 5로 나온 것보다 2배가 나쁜 도메인에서 쓰기 적합한 산식\n",
    "\n",
    "- 1) 에러에 따른 손실이 선형적으로 올라갈 때, 2)이상치가 많을 때 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F7iz5k%2FbtqPQt7tjwK%2FwW4Xugkr8jYlAJ33o9WxhK%2Fimg.jpg\">\n",
    "\n",
    "- 실제 값과 예측 값의 차이를 제곱해 평균화\n",
    "\n",
    "- 예측값과 실제값 차이의 면적의 합\n",
    "\n",
    "- 특이값이 존재하면 수치가 많이 늘어남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE 값은 오류의 제곱을 구하므로 실제 오류 평균보다 더 커지는 특성이 있어 MSE에 루트를 씌운 RMSE 값을 사용함\n",
    "\n",
    "- 에러에 제곱을 하기 때문에 에러가 크면 클수록 그에 따른 가중치가 높이 반영됨. 따라서 예측 결과물의 에러가 10이 나온 것이 5로 나온 것보다, 정확히 2**2 배가 나쁜 도메인에서 쓰기 적합한 산식\n",
    "\n",
    "- 에러에 따른 손실이 기하 급수적으로 올라가는 상황에서 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) MSLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE에 로그를 적용해준 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "msle = mean_squared_log_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbT9d4i%2FbtqPTDBKfSs%2FNJYQp4VNSiPKqmzBz2Bds0%2Fimg.jpg\">\n",
    "\n",
    "- MAE를 퍼센트로 변환. 즉, 오차가 예측값에서 차지하는 비율(%)\n",
    "\n",
    "- MAE와 같은 단점\n",
    "\n",
    "- 모델에 대한 편향이 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수식 (함수 구현)\n",
    "import numpy as np\n",
    "def MAPE(y_test, y_pred):\n",
    "    mape = np.mean(np.abs((y_test - y_pred)/y_test)) * 100\n",
    "    return mape\n",
    "mape = MAPE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6) MPE (Mean Percentage Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCmKgn%2FbtqPYSLBLub%2F6oSuG6bvsuxnkwGuCrFMm0%2Fimg.jpg\">\n",
    "\n",
    "- MAPE에서 절대값을 제외한 지표\n",
    "\n",
    "- 모델이 underperformance(+) 인지 overperformance(-) 인지 판단"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
